# settings.yaml
# Unified configuration for the GraphRAG pipeline

llm:
  type: openai_chat
  api_key: ${OPENAI_API_KEY}
  model: gpt-4.1-mini-2025-04-14
  max_tokens: 16384
  temperature: 0.0
  # Additional parameters like organization, base_url can be added here

embeddings:
  type: openai_embedding
  api_key: ${OPENAI_API_KEY}
  model: text-embedding-3-small
  batch_size: 16

input:
  type: file
  file_type: csv
  base_dir: "." # Relative to the graphrag_data directory
  file_pattern: "city_clerk_documents.csv"
  text_column: "text"
  title_column: "title"
  id_column: "id"

storage:
  type: file
  base_dir: "./output" # Relative to the graphrag_data directory

cache:
  type: file
  base_dir: "./cache" # Relative to the graphrag_data directory

chunks:
  size: 1024
  overlap: 256
  group_by_columns: ["document_type", "meeting_date"]

entity_extraction:
  prompt: "prompts/entity_extraction.txt"
  entity_types:
    - "person"
    - "organization"
    - "location"
    - "event"
    - "document"
    - "agenda_item"
    - "ordinance"
    - "resolution"
    - "document_number"
  max_gleanings: 3

# Other pipeline sections (claim_extraction, community_reports, etc.) follow... 